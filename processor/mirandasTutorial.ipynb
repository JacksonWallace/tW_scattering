{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import glob\n",
    "import re\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "import uproot\n",
    "import uproot_methods\n",
    "import awkward\n",
    "import pandas as pd\n",
    "from klepto.archives import dir_archive\n",
    "\n",
    "\n",
    "import coffea.processor as processor\n",
    "from coffea.processor.accumulator import AccumulatorABC\n",
    "from coffea import hist\n",
    "from coffea.analysis_objects import JaggedCandidateArray\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this cell for plotting NN score\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "import re\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "from klepto.archives import dir_archive\n",
    "\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import coffea.processor as processor\n",
    "from coffea.processor.accumulator import AccumulatorABC\n",
    "from coffea.analysis_objects import JaggedCandidateArray\n",
    "from coffea.btag_tools import BTagScaleFactor\n",
    "from coffea import hist\n",
    "import pandas as pd\n",
    "import uproot_methods\n",
    "import uproot\n",
    "import awkward\n",
    "import copy\n",
    "\n",
    "from memory_profiler import profile\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "from Tools.config_helpers import *\n",
    "from Tools.helpers import mergeArray\n",
    "\n",
    "from Tools.objects import Collections\n",
    "from Tools.cutflow import Cutflow\n",
    "\n",
    "# This just tells matplotlib not to open any\n",
    "# interactive windows.\n",
    "matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "def pad_and_flatten(val): \n",
    "    try:\n",
    "        return val.pad(1, clip=True).fillna(0.).flatten()#.reshape(-1, 1)\n",
    "    except AttributeError:\n",
    "        return val.flatten()\n",
    "\n",
    "#model = tf.keras.models.load_model('../ML/data/training.h5')#, custom_objects=None, compile=False)\n",
    "\n",
    "#model._make_predict_function()\n",
    "#graph = tf.get_default_graph()\n",
    "\n",
    "#def run_model(inputs):\n",
    "#    global graph\n",
    "#    with graph.as_default():\n",
    "#        outputs = model.predict(inputs)\n",
    "#    return outputs\n",
    "\n",
    "os.environ['KERAS_BACKEND'] = 'theano'\n",
    "from keras.models import load_model\n",
    "\n",
    "#model = load_model('../ML/data/training.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.setrecursionlimit(10000)\n",
    "print(sys.getrecursionlimit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's define our processor first. \n",
    "\n",
    "class WHhadProcessor(processor.ProcessorABC):\n",
    "    def __init__(self):\n",
    "        \n",
    "        ## load the NN\n",
    "        self.model = load_model('../ML/data/lostLep_Z_backgrounds/training.h5')\n",
    "        self.stds  = pd.read_json('../ML/data/lostLep_Z_backgrounds/stds.json').squeeze()\n",
    "        self.means = pd.read_json('../ML/data/lostLep_Z_backgrounds/means.json').squeeze()\n",
    "        \n",
    "        #Great, now let's define some bins for our histograms.\n",
    "        \n",
    "        dataset_axis         = hist.Cat(\"dataset\", \"Primary dataset\")\n",
    "        pt_axis              = hist.Bin(\"pt\", r\"$p_{T}$ (GeV)\", 500, 0, 2000)\n",
    "        multiplicity_axis    = hist.Bin(\"multiplicity\", r\"N\", 30, -0.5, 29.5)\n",
    "        phi_axis             = hist.Bin(\"phi\", r\"$\\Delta \\phi$\", 80, 0, 8)\n",
    "        mass_axis            = hist.Bin(\"mass\", r\"mass (GeV)\", 500, 0, 2000)\n",
    "        r_axis               = hist.Bin(\"r\", r\"$\\Delta R$\", 80, 0, 4)\n",
    "        score_axis           = hist.Bin(\"score\", r\"NN Score\", 10, 0, 1)\n",
    "\n",
    "        #In order to create proper histograms, we always need to include a dataset axis!\n",
    "        #For different types of histograms with different scales, I create axis to fit \n",
    "        #those dimensions!\n",
    "        \n",
    "        #Now, let's move to actually telling our processor what histograms we want to make.\n",
    "        #Let's start out simple. \n",
    "        self._accumulator = processor.dict_accumulator({\n",
    "            #\"met\":                          hist.Hist(\"Counts\", dataset_axis, pt_axis),\n",
    "            #\"ht\":                           hist.Hist(\"Counts\", dataset_axis, pt_axis),\n",
    "            #\"jet_pt\":                       hist.Hist(\"Counts\", dataset_axis, pt_axis),\n",
    "            #\"njets\":                        hist.Hist(\"Counts\", dataset_axis, multiplicity_axis),\n",
    "            #\"bjets\":                        hist.Hist(\"Counts\", dataset_axis, multiplicity_axis),\n",
    "            #\"min_dphi_met_j1\":              hist.Hist(\"Counts\", dataset_axis, phi_axis),\n",
    "            #\"min_dphi_met_j2\":              hist.Hist(\"Counts\", dataset_axis, phi_axis),\n",
    "            #\"min_dphi_met_j3\":              hist.Hist(\"Counts\", dataset_axis, phi_axis),\n",
    "            #\"min_dphi_met_j4\":              hist.Hist(\"Counts\", dataset_axis, phi_axis),\n",
    "            #\"dphi_j1_j2\":                   hist.Hist(\"Counts\", dataset_axis, phi_axis),\n",
    "            #\"dphi_fj1_fj2\":                 hist.Hist(\"Counts\", dataset_axis, phi_axis),\n",
    "            #\"dR_fj1_fj2\":                   hist.Hist(\"Counts\", dataset_axis, r_axis),\n",
    "            \"NN_score\":                     hist.Hist(\"Counts\", dataset_axis, score_axis),\n",
    "            #\"NN_sel\":                     hist.Hist(\"Counts\", dataset_axis, score_axis),\n",
    "            #\"NN_sel_mt\":                     hist.Hist(\"Counts\", dataset_axis, score_axis),\n",
    "            #\"NN_sel_met\":                     hist.Hist(\"Counts\", dataset_axis, score_axis),\n",
    "            #\"NN_sel_fatjet\":                     hist.Hist(\"Counts\", dataset_axis, score_axis),\n",
    "            #\"NN_sel_bjet\":                     hist.Hist(\"Counts\", dataset_axis, score_axis),\n",
    "            #\"NN_sel_mindphi\":                     hist.Hist(\"Counts\", dataset_axis, score_axis),\n",
    "            #\"NN_sel_jetdphi\":                     hist.Hist(\"Counts\", dataset_axis, score_axis),\n",
    "            #\"NN_sel_met_mt\":                     hist.Hist(\"Counts\", dataset_axis, score_axis),\n",
    "            #\"NN_sel_met_mt_fatjet\":                     hist.Hist(\"Counts\", dataset_axis, score_axis),\n",
    "            #\"NN_sel_met_mt_fatjet_bjet\":                     hist.Hist(\"Counts\", dataset_axis, score_axis),\n",
    "            #\"NN_sel_mindphi_jetdphi\":                     hist.Hist(\"Counts\", dataset_axis, score_axis),\n",
    "            #\"m_FatJet_softdrop\":            hist.Hist(\"Counts\", dataset_axis, mass_axis),\n",
    "\n",
    "        })\n",
    "\n",
    "    #Make sure to plug in the dataset axis and the properly binned axis you created above.\n",
    "    #Cool. Now let's define some properties of the processor.\n",
    "    \n",
    "    @property\n",
    "    \n",
    "    #First is this guy. He does important things so always include him. \n",
    "    def accumulator(self):\n",
    "        return self._accumulator\n",
    "\n",
    "    #Now comes the fun part. Here's where we tell our processor exactly what to do with the data.\n",
    "    def process(self, df):\n",
    "     \n",
    "        #Make sure to declare your output, which stores everything you put into the histograms.\n",
    "        output = self.accumulator.identity()\n",
    "        \n",
    "        #Load your data for the dataset axis.\n",
    "        dataset = df['dataset']\n",
    "\n",
    "        #Let's define some variables from our dataset, starting with MET.\n",
    "        metphi = df[\"MET_phi\"]\n",
    "        metpt = df[\"MET_pt\"]\n",
    "        #Here, I'm simply calling those nanoaod branches from the samples\n",
    "        #and storing them under easy to access variable names. \n",
    "        \n",
    "      \n",
    "        \n",
    "        #Let's define some 4 vector objects. For these I can call the branches whatever \n",
    "        #I want. Just make sure to include the .content at the end. Also, by making these\n",
    "        #objects, we can call the branches in a pretty easy way. Shown below.\n",
    "        \n",
    "        #Leptons\n",
    "        electrons = JaggedCandidateArray.candidatesfromcounts(\n",
    "            df['nElectron'],\n",
    "            pt=df['Electron_pt'].content, \n",
    "            eta=df['Electron_eta'].content, \n",
    "            phi=df['Electron_phi'].content,\n",
    "            mass=df['Electron_mass'].content,\n",
    "            pdgid=df['Electron_pdgId'].content,\n",
    "            mini_iso=df['Electron_miniPFRelIso_all'].content\n",
    "        )\n",
    "        \n",
    "\n",
    "        muons = JaggedCandidateArray.candidatesfromcounts(\n",
    "            df['nMuon'],\n",
    "            pt=df['Muon_pt'].content, \n",
    "            eta=df['Muon_eta'].content, \n",
    "            phi=df['Muon_phi'].content,\n",
    "            mass=df['Muon_mass'].content,\n",
    "            pdgid=df['Muon_pdgId'].content,\n",
    "            mini_iso=df['Muon_miniPFRelIso_all'].content, \n",
    "            looseid =df['Muon_looseId'].content\n",
    "        )\n",
    "        \n",
    "        taus = JaggedCandidateArray.candidatesfromcounts(\n",
    "            df['nTau'],\n",
    "            pt=df['Tau_pt'].content, \n",
    "            eta=df['Tau_eta'].content, \n",
    "            phi=df['Tau_phi'].content,\n",
    "            mass=df['Tau_mass'].content,\n",
    "            decaymode=df['Tau_idDecayMode'].content,\n",
    "            newid=df['Tau_idMVAnewDM2017v2'].content,\n",
    "        )\n",
    "        \n",
    "        #Here, since I don't have enough information to form a 4 vector with isotracks,\n",
    "        #I just use the JaggedArray format. I call branches in the same way as the\n",
    "        #JaggedCandidateArray, but I can't use some of the manipulations that come with the\n",
    "        #JCA format. :(\n",
    "        isotracks = awkward.JaggedArray.zip(\n",
    "            pt=df['IsoTrack_pt'], \n",
    "            eta=df['IsoTrack_eta'], \n",
    "            phi=df['IsoTrack_phi'], \n",
    "            rel_iso=df['IsoTrack_pfRelIso03_all'], \n",
    "        )\n",
    "        \n",
    "        #Jets\n",
    "        jets = JaggedCandidateArray.candidatesfromcounts(\n",
    "            df['nJet'],\n",
    "            pt=df['Jet_pt'].content, \n",
    "            eta=df['Jet_eta'].content, \n",
    "            phi=df['Jet_phi'].content,\n",
    "            btag=df['Jet_btagDeepB'].content, \n",
    "            jetid=df['Jet_jetId'].content, \n",
    "            mass=df['Jet_mass'].content,\n",
    "        )\n",
    "        fatjets = JaggedCandidateArray.candidatesfromcounts(\n",
    "            df['nFatJet'],\n",
    "            pt=df['FatJet_pt'].content, \n",
    "            eta=df['FatJet_eta'].content, \n",
    "            phi=df['FatJet_phi'].content, \n",
    "            mass=df['FatJet_mass'].content, \n",
    "            softdrop=df[\"FatJet_msoftdrop\"].content,  \n",
    "            fromH = df['FatJet_deepTagMD_HbbvsQCD'].content, \n",
    "            fromW_MD = df['FatJet_deepTagMD_WvsQCD'].content, \n",
    "            fromW_MC = df['FatJet_deepTag_WvsQCD'].content\n",
    "        )\n",
    "  \n",
    "        \n",
    "        #Now let's deal with some good ol' ak4's baby. Let's define a \"good jet\".\n",
    "        #First, let's define what a good jet should be. Notice how I'm calling the branches\n",
    "        #of the jets. Super easy, right?\n",
    "        goodjcut = ((jets.pt>30) & (abs(jets.eta)<2.4) & (jets.jetid>0))\n",
    "        #Perfect, now let's apply this selection to the ak4's and create a new object.\n",
    "        goodjets = jets[goodjcut]\n",
    "        #LIT. Okay, now I want the number of good jets. \n",
    "        njets = goodjets.counts\n",
    "        #Bro, you are on fire. Good job. I'm proud of you and really appreciate you.\n",
    "\n",
    "        jetpt_sorted = goodjets.pt.argsort(ascending=False)\n",
    "        leadjet = goodjets[jetpt_sorted==0]\n",
    "        subleadjet = goodjets[jetpt_sorted==1]\n",
    "        leadjet_subleadjet = leadjet.cross(subleadjet)\n",
    "        \n",
    "        lead_jet_pt = leadjet.pt\n",
    "        sublead_jet_pt = subleadjet.pt\n",
    "        #leadjets = goodjets[jetpt_sorted <= 1]\n",
    "        #leadjets3 = goodjets[jetpt_sorted <= 2]\n",
    "        #leadjets4 = goodjets[jetpt_sorted <= 4]\n",
    "      \n",
    "        #ak8's\n",
    "        goodfjcut = ((fatjets.pt > 200))\n",
    "        goodfatjets = fatjets[goodfjcut]\n",
    "        nfatjets = goodfatjets.counts\n",
    "        \n",
    "        htagcut = ((fatjets.pt > 200) & (fatjets.fromH > 0.8365))\n",
    "        htagged = fatjets[htagcut]\n",
    "        \n",
    "        wtagcut_mc = ((fatjets.pt > 200) & (fatjets.fromW_MC > 0.918) & (fatjets.fromH < 0.8365))\n",
    "        wtagcut_md = ((fatjets.pt > 200) & (fatjets.fromW_MD > 0.704) & (fatjets.fromH < 0.8365))\n",
    "        wtagged_mc = fatjets[wtagcut_mc]\n",
    "        wtagged_md = fatjets[wtagcut_md]\n",
    "\n",
    "        fatjet_sorted = goodfatjets.pt.argsort(ascending=False)\n",
    "        leadFatJet    = goodfatjets[fatjet_sorted==0]\n",
    "        subleadFatJet = goodfatjets[fatjet_sorted==1]\n",
    "        lead_sublead_FatJets = leadFatJet.cross(subleadFatJet)\n",
    "        \n",
    "        m_lead_FatJet_softdrop = goodfatjets[goodfatjets.pt.argmax()]\n",
    "    \n",
    "        #Let's make some b-jets and find the number of b-jets.\n",
    "        bjcut = ((jets.pt>30) & (abs(jets.eta)<2.4) & (jets.jetid>0) & (jets.btag>0.4184))\n",
    "        bjets = jets[bjcut]\n",
    "        nbjets = bjets.counts\n",
    "        bjetpt = bjets.pt\n",
    "        bjetpt_sorted = bjetpt.argsort(ascending=False)\n",
    "        leadbjets = bjets[bjetpt_sorted <= 1]\n",
    "        #Hell yeah. \n",
    "        \n",
    "        #Let's go for HT now. \n",
    "        ht = goodjets.pt.sum()\n",
    "        met_sig = metpt/np.sqrt(ht)\n",
    "        #Remember to put that () after the sum!\n",
    "          \n",
    "        #dphi_met_leadjs3 = abs((leadjets3.phi - metphi + np.pi) % (2 * np.pi) - np.pi)\n",
    "        #sorted_dphi_met_leadjs3 = dphi_met_leadjs3.argsort(ascending=True)\n",
    "        #min_dphi_met_leadjs3 = dphi_met_leadjs3[sorted_dphi_met_leadjs3==0]\n",
    "        #abs_min_dphi_met_leadjs3 = abs(min_dphi_met_leadjs3)\n",
    "       \n",
    "        abs_min_dphi_met_leadjs1 = abs(np.arccos(np.cos(goodjets[:,:1].phi-metphi)).min())\n",
    "        abs_min_dphi_met_leadjs2 = abs(np.arccos(np.cos(goodjets[:,:2].phi-metphi)).min())\n",
    "        abs_min_dphi_met_leadjs3 = abs(np.arccos(np.cos(goodjets[:,:3].phi-metphi)).min())\n",
    "        abs_min_dphi_met_leadjs4 = abs(np.arccos(np.cos(goodjets[:,:4].phi-metphi)).min())\n",
    "\n",
    "        abs_dphi_j1_j2           = abs(leadjet_subleadjet.i0.p4.delta_phi(leadjet_subleadjet.i1.p4))\n",
    "        abs_dphi_fj1_fj2         = abs(lead_sublead_FatJets.i0.p4.delta_phi(lead_sublead_FatJets.i1.p4))\n",
    "\n",
    "        dR_fj1_fj2               = lead_sublead_FatJets.i0.p4.delta_r(lead_sublead_FatJets.i1.p4)\n",
    "\n",
    "        ## evaluate NN\n",
    "        # first, prepare the inputs.\n",
    "        # A .max() can ensure that the flattened array has the full length, but we rather use our pad_and_flatten function        \n",
    "        # sorting in training: ['mll', 'njet', 'nbtag', 'st', 'ht', 'met', 'mjj_max', 'mlb_min', 'mlb_max', 'l0_pt', 'l1_pt', 'deltaR_lj_min', 'j0_pt']\n",
    "        \n",
    "        NN_inputs = np.stack([\n",
    "            # normalize\n",
    "            pad_and_flatten( (metpt - self.means['met'])/self.stds['met'] ),\n",
    "            pad_and_flatten( (ht - self.means['ht'])/self.stds['ht'] ),\n",
    "            pad_and_flatten( (lead_jet_pt - self.means['lead_jet_pt'])/self.stds['lead_jet_pt'] ),\n",
    "            pad_and_flatten( (sublead_jet_pt - self.means['sublead_jet_pt'])/self.stds['sublead_jet_pt'] ),\n",
    "            pad_and_flatten( (njets - self.means['njets'])/self.stds['njets'] ),\n",
    "            pad_and_flatten( (nbjets - self.means['bjets'])/self.stds['bjets'] ),\n",
    "            pad_and_flatten( (wtagged_mc.counts - self.means['nWs'])/self.stds['nWs'] ),\n",
    "            pad_and_flatten( (htagged.counts - self.means['nHs'])/self.stds['nHs'] ),\n",
    "            pad_and_flatten( (nfatjets - self.means['nFatJets'])/self.stds['nFatJets'] ),\n",
    "            pad_and_flatten( (met_sig - self.means['met_significance'])/self.stds['met_significance'] ),\n",
    "            pad_and_flatten( (abs_min_dphi_met_leadjs4 - self.means['min_dphi_met_j4'])/self.stds['min_dphi_met_j4'] ),\n",
    "        ])\n",
    "        \n",
    "        NN_inputs = np.moveaxis(NN_inputs, 0, 1)\n",
    "        NN_score = self.model.predict(NN_inputs)\n",
    "        \n",
    "        #MT      \n",
    "        dphi_leadbs_met = abs((leadbjets.phi - metphi + np.pi) % (2 * np.pi) - np.pi)\n",
    "        mt_b_met = np.sqrt(2*leadbjets.pt*metpt*(1-np.cos(dphi_leadbs_met)))\n",
    "\n",
    "        sorted_min_mt_b_met = mt_b_met.argsort(ascending=True)\n",
    "        sorted_max_mt_b_met = mt_b_met.argsort(ascending=False)\n",
    "        min_mt_b_met = mt_b_met[sorted_min_mt_b_met == 0]\n",
    "        max_mt_b_met = mt_b_met[sorted_max_mt_b_met == 0]\n",
    "\n",
    "        #Let's define lepton vetos using the same method.\n",
    "        \n",
    "        veto_e_cut = (electrons.pt>5) & (abs(electrons.eta) < 2.4) & (electrons.mini_iso < 0.2)\n",
    "        veto_e = electrons[veto_e_cut]\n",
    "        \n",
    "        veto_m_cut = (muons.pt > 5) & (abs(muons.eta) < 2.4) & (muons.looseid) & (muons.mini_iso < 0.2)\n",
    "        veto_m = muons[veto_m_cut]\n",
    "        \n",
    "        veto_t_cut = (taus.pt > 20) & (abs(taus.eta) < 2.4) & (taus.decaymode) & (taus.newid >= 8)\n",
    "        veto_t = taus[veto_t_cut]\n",
    "        \n",
    "        veto_it_cut = (isotracks.pt > 10) & (abs(isotracks.eta) < 2.4) & ((isotracks.rel_iso < (0.1*isotracks.pt)) | (isotracks.rel_iso < 6))\n",
    "        veto_it = isotracks[veto_it_cut]\n",
    "        \n",
    "       \n",
    "       \n",
    "        #Now it's time to make some selections. I'm going to guess that you can follow\n",
    "        #what I'm doing from here. \n",
    "\n",
    "        #ht_ps = (ht > 300)\n",
    "        ht_ps = (ht > 400)\n",
    "        met_ps = (metpt>250)\n",
    "        high_met_ps = (metpt>350)\n",
    "        njet_ps = (njets >= 2)\n",
    "        bjet_ps = (nbjets >= 1)\n",
    "        inc_bjet_ps = (nbjets >= 1)\n",
    "        fatjet_sel = (nfatjets >=1)\n",
    "        inc_fatjet_sel = (nfatjets >=2)\n",
    "        mt_sel = (min_mt_b_met > 200).any()\n",
    "        \n",
    "        min_dphi_sel = (abs_min_dphi_met_leadjs4 > 0.5)\n",
    "        dphi_sel = (abs_dphi_j1_j2.min() < 2.5)\n",
    "        fatjet_dphi_sel = (abs_dphi_fj1_fj2 < 2.5).all()\n",
    "\n",
    "        e_sel = (veto_e.counts == 0)\n",
    "        m_sel = (veto_m.counts == 0)\n",
    "        it_sel = (veto_it.counts == 0)\n",
    "        t_sel = (veto_t.counts == 0)\n",
    "        l_sel = e_sel & m_sel & it_sel & t_sel\n",
    "        \n",
    "        h_sel =(htagged.counts > 0) \n",
    "        wmc_sel = (wtagged_mc.counts > 0) \n",
    "\n",
    "        \n",
    "        #sel = ht_ps & met_ps & njet_ps & bjet_ps & l_sel & h_sel & wmc_sel\n",
    "        sel = ht_ps & met_ps & njet_ps & bjet_ps & fatjet_sel & l_sel & h_sel & min_dphi_sel & dphi_sel & fatjet_dphi_sel\n",
    "\n",
    "        '''nn_sel = ht_ps & met_ps & njet_ps & bjet_ps & l_sel & fatjet_sel & h_sel #& wmc_sel\n",
    "        nn_sel_mt = ht_ps & met_ps & njet_ps & bjet_ps & l_sel & fatjet_sel & mt_sel & h_sel #& wmc_sel\n",
    "        nn_sel_met = ht_ps & high_met_ps & njet_ps & bjet_ps & l_sel & fatjet_sel & h_sel #& wmc_sel\n",
    "        nn_sel_fatjet = ht_ps & high_met_ps & njet_ps & bjet_ps & l_sel & inc_fatjet_sel & h_sel #& wmc_sel\n",
    "        nn_sel_bjet = ht_ps & high_met_ps & njet_ps & inc_bjet_ps & l_sel & fatjet_sel & h_sel #& wmc_sel\n",
    "        nn_sel_mindphi = ht_ps & met_ps & njet_ps & bjet_ps & l_sel & fatjet_sel & h_sel & min_dphi_sel #& wmc_sel\n",
    "        nn_sel_jetdphi = ht_ps & met_ps & njet_ps & bjet_ps & l_sel & fatjet_sel & h_sel & dphi_sel #& wmc_sel\n",
    "        nn_sel_met_mt = ht_ps & high_met_ps & njet_ps & bjet_ps & l_sel & fatjet_sel & mt_sel & h_sel #& wmc_sel\n",
    "        nn_sel_met_mt_fatjet = ht_ps & high_met_ps & njet_ps & bjet_ps & l_sel & inc_fatjet_sel & mt_sel & h_sel #& wmc_sel\n",
    "        nn_sel_met_mt_fatjet_bjet = ht_ps & high_met_ps & njet_ps & inc_bjet_ps & l_sel & inc_fatjet_sel & mt_sel & h_sel #& wmc_sel\n",
    "        nn_sel_mindphi_jetdphi = ht_ps & met_ps & njet_ps & bjet_ps & l_sel & fatjet_sel & h_sel & min_dphi_sel & dphi_sel #& wmc_sel'''\n",
    "            \n",
    "    \n",
    "        #Let's make sure we weight our events properly.\n",
    "        wght = df['weight'][sel] * 137\n",
    "        '''nn_wght = df['weight'][nn_sel] * 137\n",
    "        nn_mt_wght = df['weight'][nn_sel_mt] * 137\n",
    "        nn_met_wght = df['weight'][nn_sel_met] * 137\n",
    "        nn_fatjet_wght = df['weight'][nn_sel_fatjet] * 137\n",
    "        nn_bjet_wght = df['weight'][nn_sel_bjet] * 137\n",
    "        nn_mindphi_wght = df['weight'][nn_sel_mindphi] * 137\n",
    "        nn_jetdphi_wght = df['weight'][nn_sel_jetdphi] * 137\n",
    "        nn_met_mt_wght = df['weight'][nn_sel_met_mt] * 137\n",
    "        nn_met_mt_fatjet_wght = df['weight'][nn_sel_met_mt_fatjet] * 137\n",
    "        nn_met_mt_fatjet_bjet_wght = df['weight'][nn_sel_met_mt_fatjet_bjet] * 137\n",
    "        nn_mindphi_jetdphi_wght = df['weight'][nn_sel_mindphi_jetdphi] * 137\n",
    "        '''#fj_wght = ((fatjets[sel].pt>0)*df['weight'][sel].flatten()) * 137\n",
    "        #Since the weight will be the same for the entire dataset, I call the first \n",
    "        #element of the weight branch. This lets me bypass any issues I may come across\n",
    "        #when I have arrays of different sizes than my weight branch. \n",
    "        \n",
    "        \n",
    "        #Let's fill some histograms. \n",
    "        '''output['met'].fill(dataset=dataset, pt=metpt[sel].flatten(), weight=wght)\n",
    "        output['ht'].fill(dataset=dataset, pt=ht[sel].flatten(), weight=wght)\n",
    "        #output['jet_pt'].fill(dataset=dataset, pt=jetpt_sorted[sel].flatten(), weight=wght)\n",
    "        output['njets'].fill(dataset=dataset, multiplicity=njets[sel].flatten(), weight=wght)\n",
    "        output['bjets'].fill(dataset=dataset, multiplicity=nbjets[sel].flatten(), weight=wght)   \n",
    "        output['min_dphi_met_j1'].fill(dataset=dataset, phi=abs_min_dphi_met_leadjs1[sel].flatten(), weight=wght)\n",
    "        output['min_dphi_met_j2'].fill(dataset=dataset, phi=abs_min_dphi_met_leadjs2[sel].flatten(), weight=wght)\n",
    "        output['min_dphi_met_j3'].fill(dataset=dataset, phi=abs_min_dphi_met_leadjs3[sel].flatten(), weight=wght)\n",
    "        output['min_dphi_met_j4'].fill(dataset=dataset, phi=abs_min_dphi_met_leadjs4[sel].flatten(), weight=wght)\n",
    "        output['dphi_j1_j2'].fill(dataset=dataset, phi=abs_dphi_j1_j2[sel].flatten(), weight=wght)'''\n",
    "        #output['dphi_fj1_fj2'].fill(dataset=dataset, phi=abs_dphi_fj1_fj2[sel].flatten(), weight=wght)\n",
    "        #output['dR_fj1_fj2'].fill(dataset=dataset, r=dR_fj1_fj2[sel].flatten(), weight=wght)\n",
    "        output['NN_score'].fill(dataset=dataset, score=NN_score[sel].flatten(), weight=wght)\n",
    "        '''output['NN_sel'].fill(dataset=dataset, score=NN_score[nn_sel].flatten(), weight=nn_wght)\n",
    "        output['NN_sel_mt'].fill(dataset=dataset, score=NN_score[nn_sel_mt].flatten(), weight=nn_mt_wght)\n",
    "        output['NN_sel_met'].fill(dataset=dataset, score=NN_score[nn_sel_met].flatten(), weight=nn_met_wght)\n",
    "        output['NN_sel_fatjet'].fill(dataset=dataset, score=NN_score[nn_sel_fatjet].flatten(), weight=nn_fatjet_wght)\n",
    "        output['NN_sel_bjet'].fill(dataset=dataset, score=NN_score[nn_sel_bjet].flatten(), weight=nn_bjet_wght)\n",
    "        output['NN_sel_mindphi'].fill(dataset=dataset, score=NN_score[nn_sel_mindphi].flatten(), weight=nn_mindphi_wght)\n",
    "        output['NN_sel_jetdphi'].fill(dataset=dataset, score=NN_score[nn_sel_jetdphi].flatten(), weight=nn_jetdphi_wght)\n",
    "        output['NN_sel_met_mt'].fill(dataset=dataset, score=NN_score[nn_sel_met_mt].flatten(), weight=nn_met_mt_wght)\n",
    "        output['NN_sel_met_mt_fatjet'].fill(dataset=dataset, score=NN_score[nn_sel_met_mt_fatjet].flatten(), weight=nn_met_mt_fatjet_wght)\n",
    "        output['NN_sel_met_mt_fatjet_bjet'].fill(dataset=dataset, score=NN_score[nn_sel_met_mt_fatjet_bjet].flatten(), weight=nn_met_mt_fatjet_bjet_wght)\n",
    "        output['NN_sel_mindphi_jetdphi'].fill(dataset=dataset, score=NN_score[nn_sel_mindphi_jetdphi].flatten(), weight=nn_mindphi_jetdphi_wght)\n",
    "        '''#output['m_FatJet_softdrop'].fill(dataset=dataset, mass=fatjets[sel].softdrop.flatten(), weight=fj_wght)\n",
    "        #Notice I have put .flatten() next to the data I'm inputting. This makes my\n",
    "        #data arrays the appropriate format to input into histograms. \n",
    "        \n",
    "        #Return that output, hunty!\n",
    "        return output\n",
    "\n",
    "    #Remember this bad boy and we're done with this block of code!\n",
    "    \n",
    "    def postprocess(self, accumulator):\n",
    "        return accumulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f52574303e164a75a9eb983b723f8b0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(HTML(value='Processing'), FloatProgress(value=0.0, max=394.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fileset   = {'mC750_l1': glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/0p1p20/WH_had_750_1_nanoAOD/*.root'),\n",
    "            'WJets': glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/0p1p20/WJetsToLNu*/*.root'),\n",
    "            'QCD': glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/0p1p20/QCD_HT*/*.root'),\n",
    "            'TTJets': glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/0p1p20/TTJets*/*.root'),\n",
    "            'ZNuNu': glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/0p1p20/ZJetsToNuNu*/*.root'),\n",
    "            'ST':glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/0p1p20/ST*/*.root'),\n",
    "            'ttW/ttZ':glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/0p1p20/ttWJets*/*.root')\n",
    "                +glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/0p1p20/ttZJets*/*.root'),\n",
    "            'WW/WZ/ZZ':glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/0p1p20/WW*/*.root')\n",
    "                +glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/0p1p20/WZ*/*.root')\n",
    "                +glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/0p1p20/ZZTo2L2Nu*/*.root')\n",
    "                +glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/0p1p20/ZZTo2Q2Nu*/*.root')\n",
    "                }\n",
    "\n",
    "#Here, I've separated by data from my background. This lets me change the style of the\n",
    "#signal line and keep the background consistent. \n",
    "\n",
    "output = processor.run_uproot_job(fileset,\n",
    "                                    treename='Events',\n",
    "                                    processor_instance=WHhadProcessor(),\n",
    "                                    executor=processor.futures_executor,\n",
    "                                    executor_args={'workers': 12, 'function_args': {'flatten': False}},\n",
    "                                    chunksize=500000,\n",
    "                                 )\n",
    "\n",
    "#Here, we have the ability to change the 'workers' and 'chunksize', but to be honest,\n",
    "#it does not make that much of a difference unless you want to see your progress bar \n",
    "#get updates more or less often. Totally a person choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here's a block to help you make some pretty histos. This deals solely with style.\n",
    "#These first two variables define my signal line as red and defines the error bar style I want!\n",
    "lineopts = {\n",
    "    'color': 'r',\n",
    "}\n",
    "\n",
    "data_err_opts = {\n",
    "    'linestyle': 'none',\n",
    "    'marker': '_',\n",
    "    'markersize': 10.,\n",
    "    'color': 'r',\n",
    "    'elinewidth': 1,\n",
    "}\n",
    "\n",
    "#Now, let's go to background. I define the line and fill color for the background because\n",
    "#I want it to be a different style from my signal. \n",
    "\n",
    "lineopts2 = {\n",
    "    'color': [('#7FB069'), ('#5171A5') ,('#E2AEDD'), ('#A33B20'), ('#680E4B'), ('#F6AE2D'),('#45503B')],\n",
    "}\n",
    "fillopts1 = {\n",
    "    'edgecolor': (0,0,0,0.3),\n",
    "    'facecolor': [('#7FB069'), ('#5171A5') ,('#E2AEDD'), ('#A33B20'), ('#680E4B'), ('#F6AE2D'),('#45503B')],\n",
    "    #'facecolor': [('#1467cc'), ('#51d673') ,('#f7d969'), ('#af84f0'), ('#4f842e'), ('#1ff4ff'),('#3612ab')],\n",
    "}\n",
    "\n",
    "#Here are two special functions I wrote to help you easily print histos to your output\n",
    "#directory. All you need to input is the signal and background histograms, the output\n",
    "#directory and the name of the histogram. \n",
    "\n",
    "def savefig(hists, outdir, name):\n",
    "    import re\n",
    "    bkgonly = re.compile('(?!mC750_l1)')\n",
    "    ax = hist.plot1d(hists[bkgonly], overlay=\"dataset\", density=False, stack=True, \n",
    "                fill_opts = fillopts1, overflow = 'over')\n",
    "    hist.plot1d(hists['mC750_l1'], overlay=\"dataset\", density=False, stack=False, \n",
    "                error_opts=data_err_opts, overflow = 'over') \n",
    "    ax.set_yscale('log')\n",
    "    ax.set_ylim(0.001,1000000)\n",
    "    ax.figure.savefig(os.path.join(outdir, \"{}_log.pdf\".format(name)))\n",
    "    ax.clear()\n",
    "\n",
    "def savefigshape(hists, outdir, name):\n",
    "    ax = hist.plot1d(hists, overlay=\"dataset\", density=True, stack=False, \n",
    "                line_opts = lineopts2, overflow = 'over')\n",
    "    \n",
    "    ax.set_yscale('log')\n",
    "    ax.set_ylim(0.00001,10)\n",
    "    ax.figure.savefig(os.path.join(outdir, \"{}_shape_log.pdf\".format(name)))\n",
    "    ax.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's remind ourselves of the histograms we created so we can loop through them \n",
    "#and create an array to loop through when we rebin. \n",
    "histograms = [#\"met\",\n",
    "              #\"ht\", \n",
    "              #\"jet_pt\", \n",
    "              #\"njets\", \n",
    "              #\"bjets\", \n",
    "              #\"min_dphi_met_j1\", \n",
    "              #\"min_dphi_met_j2\", \n",
    "              #\"min_dphi_met_j3\", \n",
    "              #\"min_dphi_met_j4\", \n",
    "              #\"dphi_j1_j2\", \n",
    "              #\"dphi_fj1_fj2\", \n",
    "              #\"dR_fj1_fj2\",\n",
    "              \"NN_score\",\n",
    "              #\"NN_sel\",\n",
    "              #\"NN_sel_mt\",\n",
    "              #\"NN_sel_met\",\n",
    "              #\"NN_sel_fatjet\",\n",
    "              #\"NN_sel_bjet\",\n",
    "              #\"NN_sel_mindphi\",\n",
    "              #\"NN_sel_jetdphi\",\n",
    "              #\"NN_sel_met_mt\",\n",
    "              #\"NN_sel_met_mt_fatjet\",\n",
    "              #\"NN_sel_met_mt_fatjet_bjet\",\n",
    "              #\"NN_sel_mindphi_jetdphi\",\n",
    "              #\"mFatJet_softdrop\"\n",
    "             ]\n",
    "\n",
    "#Make sure this points to a directory you can print to!\n",
    "outdir = \"/home/users/ksalyer/CMSSW_10_2_9/src/tW_scattering/tutorialPlots/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN_score\n"
     ]
    }
   ],
   "source": [
    "#Let's loop through these histograms and rebin! Remember to change the binning for both the\n",
    "#signal and background!!! Here I can also change the title of my plots!!\n",
    "for name in histograms:\n",
    "    print (name)\n",
    "    hists = output[name]\n",
    "    \n",
    "    '''if name == \"met\":\n",
    "        new_met_bins = hist.Bin('pt', r'MET', 26, 248, 1600)\n",
    "        hists = hists.rebin('pt', new_met_bins)\n",
    "        \n",
    "    if name == \"ht\":\n",
    "        new_ht_bins = hist.Bin('pt', r'HT', 25, 300, 2000)\n",
    "        hists = hists.rebin('pt', new_ht_bins)\n",
    "        \n",
    "    #if name == \"jet_pt\":\n",
    "        #new_jetpt_bins = hist.Bin('pt', r'jet $p_{T}$', 25, 300, 2000)\n",
    "        #hists = hists.rebin('pt', new_jetpt_bins)\n",
    "        \n",
    "    if name == \"njets\":\n",
    "        new_nj_bins = hist.Bin('multiplicity', r'nJets', 16, -0.5, 15.5)\n",
    "        hists = hists.rebin('multiplicity', new_nj_bins)\n",
    "        \n",
    "    if name == \"bjets\":\n",
    "        new_bj_bins = hist.Bin('multiplicity', r'nBJets', 7, -0.5, 6.5)\n",
    "        hists = hists.rebin('multiplicity', new_bj_bins)\n",
    "            \n",
    "    if name == \"min_dphi_met_j1\":\n",
    "        new_mdmj1_bins = hist.Bin('phi', r' $|min(\\Delta \\Phi$(MET, lead 1 jet))|', 20, 0 , 4)\n",
    "        hists = hists.rebin('phi', new_mdmj1_bins)\n",
    "            \n",
    "    if name == \"min_dphi_met_j2\":\n",
    "        new_mdmj2_bins = hist.Bin('phi', r' $|min(\\Delta \\Phi$(MET, lead 2 jets))|', 20, 0 , 4)\n",
    "        hists = hists.rebin('phi', new_mdmj2_bins)\n",
    "            \n",
    "    if name == \"min_dphi_met_j3\":\n",
    "        new_mdmj3_bins = hist.Bin('phi', r' $|min(\\Delta \\Phi$(MET, lead 3 jets))|', 20, 0 , 4)\n",
    "        hists = hists.rebin('phi', new_mdmj3_bins)\n",
    "            \n",
    "    if name == \"min_dphi_met_j4\":\n",
    "        new_mdmj4_bins = hist.Bin('phi', r' $|min(\\Delta \\Phi$(MET, lead 4 jets))|', 20, 0 , 4)\n",
    "        hists = hists.rebin('phi', new_mdmj4_bins)\n",
    "            \n",
    "    if name == \"dphi_j1_j2\":\n",
    "        new_dphij1j2_bins = hist.Bin('phi', r' $|\\Delta \\Phi$(leading 2 jets)|', 20, 0 , 4)\n",
    "        hists = hists.rebin('phi', new_dphij1j2_bins)\n",
    "            \n",
    "    #if name == \"dphi_fj1_fj2\":\n",
    "        #new_dphifj1fj2_bins = hist.Bin('phi', r' $|\\Delta \\Phi$(leading 2 FatJets)|', 20, 0 , 4)\n",
    "        #hists = hists.rebin('phi', new_dphifj1fj2_bins)\n",
    "            \n",
    "    #if name == \"dR_fj1_fj2\":\n",
    "        #new_dRfj1fj2_bins = hist.Bin('r', r' $\\Delta R$', 20, 0 , 4)\n",
    "        #hists = hists.rebin('r', new_dRfj1fj2_bins)'''\n",
    "            \n",
    "    if name == \"NN_score\":\n",
    "        new_nn_score_bins = hist.Bin('r', r'NN Score', 10, 0 , 1)\n",
    "        hists = hists.rebin('score', new_nn_score_bins)\n",
    "            \n",
    "    '''if name == \"NN_sel\":\n",
    "        new_nn_score_bins = hist.Bin('r', r'NN Score', 10, 0 , 1)\n",
    "        hists = hists.rebin('score', new_nn_score_bins)\n",
    "            \n",
    "    if name == \"NN_sel_mt\":\n",
    "        new_nn_score_bins = hist.Bin('r', r'NN Score', 10, 0 , 1)\n",
    "        hists = hists.rebin('score', new_nn_score_bins)\n",
    "            \n",
    "    if name == \"NN_sel_met\":\n",
    "        new_nn_score_bins = hist.Bin('r', r'NN Score', 10, 0 , 1)\n",
    "        hists = hists.rebin('score', new_nn_score_bins)\n",
    "            \n",
    "    if name == \"NN_sel_fatjet\":\n",
    "        new_nn_score_bins = hist.Bin('r', r'NN Score', 10, 0 , 1)\n",
    "        hists = hists.rebin('score', new_nn_score_bins)\n",
    "            \n",
    "    if name == \"NN_sel_bjet\":\n",
    "        new_nn_score_bins = hist.Bin('r', r'NN Score', 10, 0 , 1)\n",
    "        hists = hists.rebin('score', new_nn_score_bins)\n",
    "            \n",
    "    if name == \"NN_sel_mindphi\":\n",
    "        new_nn_score_bins = hist.Bin('r', r'NN Score', 10, 0 , 1)\n",
    "        hists = hists.rebin('score', new_nn_score_bins)\n",
    "            \n",
    "    if name == \"NN_sel_jetdphi\":\n",
    "        new_nn_score_bins = hist.Bin('r', r'NN Score', 10, 0 , 1)\n",
    "        hists = hists.rebin('score', new_nn_score_bins)\n",
    "            \n",
    "    if name == \"NN_sel_met_mt\":\n",
    "        new_nn_score_bins = hist.Bin('r', r'NN Score', 10, 0 , 1)\n",
    "        hists = hists.rebin('score', new_nn_score_bins)\n",
    "            \n",
    "    if name == \"NN_sel_met_mt_fatjet\":\n",
    "        new_nn_score_bins = hist.Bin('r', r'NN Score', 10, 0 , 1)\n",
    "        hists = hists.rebin('score', new_nn_score_bins)\n",
    "            \n",
    "    if name == \"NN_sel_met_mt_fatjet_bjet\":\n",
    "        new_nn_score_bins = hist.Bin('r', r'NN Score', 10, 0 , 1)\n",
    "        hists = hists.rebin('score', new_nn_score_bins)\n",
    "            \n",
    "    if name == \"NN_sel_mindphi_jetdphi\":\n",
    "        new_nn_score_bins = hist.Bin('r', r'NN Score', 10, 0 , 1)\n",
    "        hists = hists.rebin('score', new_nn_score_bins)'''\n",
    "            \n",
    "    #if name == \"mFatJet_softdrop\":\n",
    "        #new_mFatJet_softdrop_bins = hist.Bin('mass', r'FatJet softdrop mass', 12, 0 , 300)\n",
    "        #hists = hists.rebin('mass', new_mFatJet_softdrop_bins)\n",
    "        \n",
    "    savefig(hists,outdir, name)\n",
    "    savefigshape(hists,outdir, name)\n",
    "#In these last two lines, I call those special histogram functions I made! Check your\n",
    "#output directory once this is done and all your pretty plots will be there!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coffeaEnv",
   "language": "python",
   "name": "coffeaenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
